# CHAPTER 6 Advanced Topics
This chapter covers topics that are very important, but slightly more complex than the rest of the book. We will dive into adding effects to sounds, generating synthetic sound effects without any audio buffers at all, simulating effects of different acoustic（/əˈkuːstɪk/声音的，听觉的；） environments, and spatializing sound in 3D space.

# 高级主题

这一章涵盖了非常重要的主题，但比本书的其他部分稍微复杂一些。 我们会深入对声音添加音效，完全不通过任何音频缓冲来计算合成音效, 模拟不同声音环境的效果，还有关于空 3D 空间音频。


## CRITICAL THEORY Biquad Filters

A filter can emphasize or de-emphasize certain parts of the frequency spectrum(范围，幅度；光谱；波谱，频谱；余象) of a sound. Visually, it can be shown as a graph over the frequency domain called a frequency response graph (see Figure 6-1). For each frequency, the higher the value of the graph, the more emphasis is placed on that part of the frequency range. A graph sloping downward places more emphasis on low frequencies and less on high frequencies.
Web Audio filters can be configured with three parameters: gain, frequency, and a quality factor (also known as Q). These parameters all affect the frequency response graph differently.
There are many kinds of filters that can be used to achieve certain kinds of effects:


Low-pass filter
  Makes sounds more muffled
High-pass filter
  Makes sounds more tinny
Band-pass filter
  Cuts off lows and highs (e.g., telephone filter)
Low-shelf filter
  Affects the amount of bass in a sound (like the bass knob on a stereo)
High-shelf filter
  Affects the amount of treble in a sound (like the treble knob on a stereo)
Peaking filter
  Affects the amount of midrange in a sound (like the mid knob on a stereo)
Notch filter
  Removes unwanted sounds in a narrow frequency range
All-pass filter
  Creates phaser effects

All of these biquad（双四边形） filters stem from a common mathematical model and can all be graphed like the low-pass filter in Figure 6-1. More details about these filters can be found in more mathematically demanding books such as Real Sound Synthesis for Interactive Applications by Perry R. Cook (A K Peters, 2002), which I highly recommend reading if you are interested in audio fundamentals.

## 重要理论：双二阶滤波器

一个滤波可以增强或减弱声音频谱的某些部分。 直观地，在频域上它可以被表示为一个图表被称为“频率响应图”（见图 6-1）。在每一个频率上，对于每一个频率，图形的值越高，表示频率范围的那一部分越受重视。向下倾斜的图表更多地强调低频，而较少强调高频。

Web Audio 滤镜可配置3个参数： gain, frequency 和 质量因子( 常称为 Q)。这些参数全部会不同程度影响频率响应图。

有很多种滤镜可以用来达到特定的效果:

- Low-pass 滤波
  使声音更低沉

- High-pass 滤波器
  使声音更微小

- Band-pass 滤波器
  截掉低点和高点(例如，电话滤波器)  

- Low-shelf 滤波器
  影响声音中的低音量(如立体声上的低音旋钮)  

- Peaking  滤波器
  影响声音中音的数量(如立体声上的中音旋钮)

- Notch 滤波器
  去除窄频率范围内不需要的声音

- All-pass 滤波器
  创建相位效果


![images](./ch06/img/6-1.png)

图 6-1 低通滤波器的频率响应图


所有这些双二元滤波器(biquad filter)都源于一个共同的数学模型，并且都可以用图形表示, 就像低通滤波器(low-pass filter) 一样(图 6-1)。 关于更多的滤波器细节参考对数学要求更高的这本书《Real Sound Synthesis for Interactive》作者 Perry R. Cook。 如果你对音频底层原理感兴趣的话我强烈推荐你阅读它。


## Adding Effects via Filters
Using the Web Audio API, we can apply the filters discussed above using BiquadFilterNodes. This type of audio node is very commonly used to build equalizers and manipulate sounds in interesting ways. Let’s set up a simple low-pass filter to eliminate (
剔除) low frequency noise from a sound sample:

## 通过滤波器添加效果
要使用 Web Audio API ，我们可以通过应用上面提到过的 BiquadFilterNodes。

这个类型的音频节点，在创建均衡器并以有趣的方式操纵声音时应用非常普遍。让我们设置一个简单的低通滤波器(low-pass filter) 在一个声音例子中用它过滤掉低频噪声：

```
// Create a filter
var filter = context.createBiquadFilter();
// Note: the Web Audio spec is moving from constants to strings. // filter.type = 'lowpass';
filter.type = filter.LOWPASS;
filter.frequency.value = 100;
// Connect the source to it, and the filter to the destination.
```

The BiquadFilterNode has support for all of the commonly used second-order filter types. We can configure these nodes with the same parameters as discussed in the previous section, and also visualize the frequency response graphs by using the get FrequencyResponse method on the node. Given an array of frequencies, this function returns an array of magnitudes of responses corresponding to each frequency.

Chris Wilson and Chris Rogers put together a great visualizer sample (Figure 6-2) that shows the frequency responses of all of the filter types available in the Web Audio API.

BiquadFilterNode 支持所有常用的二阶过滤器类型。我们可以使用与前一节中讨论的相同的参数配置这些节点，并且还可以通过在节点上使用get FrequencyResponse方法来可视化频率响应图。给定一个频率数组，该函数返回对应于每个频率的响应幅度数组。

Chris Wilson 和 Chris Rogers 非常好的可视化例子，将所有 Web Audio API 可用的滤波器类型放到一起的频率反应图。



![images](./ch06/img/6-2.png)

图 6-2 带参数的低通滤波器的频率响应图



## Procedurally Generated Sound
Up to now, we have been assuming that your game’s sound sources are static. An audio designer creates a bunch of assets and hands them over to you. Then, you play them back with some parameterization depending on local conditions (for example, the room ambiance 
氛围，周围环境，格调；背景音 and relative positions of sources and listeners). This approach has a few disadvantages:

1. Sound assets will be very large. This is especially bad on the Web, where instead of loading from a hard drive, you load from a network (at least the first time), which is roughly an order of magnitude slower.

2. Even with many assets and tweaks to each, there is limited variety.

3. You need to find assets by scouring(搜查；擦亮；擦洗) sound effects libraries, and then maybe worry about royalties ( royalty 版权\版税 ). Plus, chances are, any given sound effect is already being used in other applications, so your users have unintended associations.

We can use the Web Audio API to fully generate sound procedurally. For example, let’s simulate a gun firing. We begin with a buffer of white noise, which we can generate with a ScriptProcessorNode as follows:

## 程序化生成声音

到目前为止，我们假定你游戏中用到的都是静态的声音。音频设计师自己创建并处理了一堆音频资源，你负责根据当前条件使用一些参数控制播放这些音频（举例，房间内的背景音和音频资源位置与听众）。这种实现方式不够先进：

1. 声音文件可能会非常大。在网页中尤其不好，与在本地磁盘加载不同，通常是通过网络加载的(特别是第一次加载时)，  简直慢了一个数量级。

2. 就算拥有多众多资源和变和简单的变形，变化种类还是有限。

3. 你需要通过搜索音效库来找到资产，然后可能还要担心版权问题.另外，很有可能，任何给定的声音效果已经在其他应用 程序中使用过，所以您的用户会产生意想不到的关联

我们完全可以利用程序使用 Web Audio API 来直接生成声音。举个例子，让我们来模拟一下枪开火的声音。我们从一个白器噪声的冲级区开始，它使用 ScriptProcessorNode 生成如下：

```
function WhiteNoiseScript() {
  this.node = context.createScriptProcessor(1024, 1, 2); 
  this.node.onaudioprocess = this.process;
}
WhiteNoiseScript.prototype.process = function(e) { 
  var L = e.outputBuffer.getChannelData(0);
  var R = e.outputBuffer.getChannelData(1);
  for (var i = 0; i < L.length; i++) {
    L[i] = ((Math.random() * 2) - 1);
    R[i] = L[i]; 
  }
};
```

This code is not an efficient implementation because JavaScript is required to constantly and dynamically create a stream of white noise. To increase efficiency, we can programmatically generate a mono AudioBuffer of white noise as follows:

上面的代码实现不够高效，因为 JavaScript 需要不断动态地创建白噪音流，为了增强效率， 我们可以以程序化的方式生成白噪声的单声道音频缓冲，如下所示：

```
function WhiteNoiseGenerated(callback) {
  // Generate a 5 second white noise buffer.
  var lengthInSamples = 5 * context.sampleRate;
  var buffer = context.createBuffer(1, lengthInSamples, context.sampleRate); 
  var data = buffer.getChannelData(0);
  for (var i = 0; i < lengthInSamples; i++) { 
    data[i] = ((Math.random() * 2) - 1);
  }
  // Create a source node from the buffer.
  this.node = context.createBufferSource(); 
  this.node.buffer = buffer;
  this.node.loop = true; 
  this.node.start(0);
}
```


Next, we can simulate various phases of the gun firing—attack, decay, and release—in an envelope:

接下来，我们可以在一个封装好的函数中模拟枪射击的各个阶段——攻击、衰减和释放：

```
function Envelope() {
  this.node = context.createGain() 
  this.node.gain.value = 0;
}
Envelope.prototype.addEventToQueue = function() {
  this.node.gain.linearRampToValueAtTime(0, context.currentTime);
  this.node.gain.linearRampToValueAtTime(1, context.currentTime + 0.001); 
  this.node.gain.linearRampToValueAtTime(0.3, context.currentTime + 0.101); 
  this.node.gain.linearRampToValueAtTime(0, context.currentTime + 0.500);
}
```

Finally, we can connect the voice outputs to a filter to allow a simulation of distance:

最后，我们可以将声音输出连接到一个滤波器，以模拟距离

```
this.voices = []; 
this.voiceIndex = 0;
var noise = new WhiteNoise();
var filter = context.createBiquadFilter();
filter.type = 0;
filter.Q.value = 1;
filter.frequency.value = 800;
// Initialize multiple voices.
for (var i = 0; i < VOICE_COUNT; i++) { 
  var voice = new Envelope(); 
  noise.connect(voice.node); 
  voice.connect(filter); 
  this.voices.push(voice);
}
var gainMaster = context.createGainNode(); 
gainMaster.gain.value = 5; 
filter.connect(gainMaster);
gainMaster.connect(context.destination);
```

This example is borrowed from BBC’s gunfire effects page with small modifications,
including a port to JavaScript.
As you can see, this approach is very powerful but gets complicated pretty quickly, going beyond the scope of this book. For more information about procedural sound generation, take a look at Andy Farnell’s Practical Synthetic Sound Design tutorials and book.

这个例子移值修改自 BBC 的开枪音效(http://webaudio.prototyping.bbc.co.uk/gunfire/) 适配 JavaScript.

正如您所看到的，这种方法非常强大，但很快就会变得复杂，超出了本书的范围. 更多关于声音的处理与生成可参考 Andy Farnell 的《Practical Synthetic Sound Design tutorials》




## Room Effects
Before sound gets from its source to our ears, it bounces off walls, buildings, furni‐ ture, carpets, and other objects. Every such collision changes properties of the sound. For example, clapping your hands outside sounds very different from clapping your hands inside a large cathedral, which can cause audible reverberations for several sec‐ onds. Games with high production value aim to imitate these effects. Creating a sepa‐ rate set of samples for each acoustic environment is often prohibitively expensive, since it requires a lot of effort from the audio designer, and a lot of assets, and thus a larger amount of game data.

The Web Audio API comes with a facility to simulate these various acoustic environ‐ ments called a ConvolverNode. Examples of effects that you can get out of the convo‐ lution engine include chorus effects, reverberation, and telephone-like speech.
















